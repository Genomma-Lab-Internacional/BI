{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import jupyternotify\n",
    "import pandas as pd\n",
    "import requests\n",
    "import calendar\n",
    "import json\n",
    "import os\n",
    "from urllib.request import urlopen\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "from time import sleep\n",
    "import pyodbc\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "from mysql.connector import errorcode\n",
    "\n",
    "ip = get_ipython()\n",
    "ip.register_magics(jupyternotify.JupyterNotifyMagics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = 'Ecuador'\n",
    "\n",
    "path = '../../01ISV/Params/'\n",
    "for json_file in [file for file in os.listdir(path) if file.endswith('.json')]:  \n",
    "    with open(path + json_file, encoding='utf8') as f:\n",
    "        globals()[json_file.split('.')[0].split('_')[1]] = json.load(f)\n",
    "\n",
    "for json_file in [file for file in os.listdir(path + country + '/') if file.endswith('.json')]:\n",
    "    with open(path + country + '/' + json_file, encoding='utf8') as f:\n",
    "        globals()[json_file.split('.')[0]] = json.load(f)\n",
    "\n",
    "for sql_file in [file for file in os.listdir(path + country + '/') if file.endswith('.sql')]:\n",
    "    globals()[sql_file.split('.')[0]] = query = open(path + country + '/' + sql_file, encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['headers_sales']['Authorization'] = 'ISVToken ' + tokens[country]\n",
    "body_sales = sales['body_sales']\n",
    "body_sales['views'] = sales['views'][country]\n",
    "body_sales['hierarchy'] = sales['hierarchy_sales'][country]\n",
    "body_sales['view_type'] = 'semana'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_stores = stores['url_stores']\n",
    "headers_stores = stores['headers_stores']\n",
    "headers_stores['Authorization'] = 'ISVToken ' + tokens[country]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_stock = stocks['url_stock']\n",
    "headers_stock = stocks['headers_stock']\n",
    "headers_stock['Authorization'] = 'ISVToken ' + tokens[country]\n",
    "hierarchy_stock = stocks['hierarchy_stock']\n",
    "body_stock = stocks['body_stock']\n",
    "body_stock['hierarchy'] = hierarchy_stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DWH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn1 = pyodbc.connect('Driver={SQL Server};'\n",
    "                     'Server=' + servers_dbs['server'] + ';'\n",
    "                     'Database=' + servers_dbs['database1'] + ';'\n",
    "                     'Trusted_Connection=yes;')\n",
    "\n",
    "conn2 = pyodbc.connect('Driver={SQL Server};'\n",
    "                     'Server=' + servers_dbs['server'] + ';'\n",
    "                     'Database=' + servers_dbs['database2'] + ';'\n",
    "                     'Trusted_Connection=yes;')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DWH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tmpid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7304, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmpid = pd.read_sql(query_dates.read(), conn1)\n",
    "df_tmpid['TmpFecha'] = df_tmpid['TmpFecha'].astype(str).copy()\n",
    "df_tmpid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ProPstID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ppst = pd.read_sql(query_ppst.read(), conn2)\n",
    "df_ppst['ProPstCodBarras'] = df_ppst['ProPstCodBarras'].astype(str).copy()\n",
    "df_ppst.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Semana ISV = Semana Genomma - 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_format = lambda number: '0' + str(number) if (number < 10) else str(number)\n",
    "\n",
    "clean_date = lambda str_date: datetime(int(str_date.split('-')[2]), int(str_date.split('-')[1]), int(str_date.split('-')[0]))\n",
    "\n",
    "clean_numbers = lambda str_numb: float(str(str_numb).replace('.','').replace(',',''))/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_status(status):\n",
    "    if status != 200:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_file(response):\n",
    "    file = urlopen(response.json()['download_url'])\n",
    "    zip_file = ZipFile(BytesIO(file.read()))\n",
    "    df = pd.read_csv(zip_file.open(zip_file.namelist()[0]), encoding='latin-1', sep=';')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_sales(num_week, url, header, body):\n",
    "    body[\"dates\"] = [\"2020-W\" + weekly_format(num_week)]\n",
    "    resp_sales = requests.post(url, data=json.dumps(body), headers=header)\n",
    "    if resp_sales.status_code != 200:\n",
    "        print(\"Oh, oh, adventurous, problems  in week \" + str(num_week) + \" :S\")\n",
    "        pass\n",
    "    else:\n",
    "        df = unpack_data(resp_sales)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sales(data):    \n",
    "    data['Cód. Cadena'] = data['Cód. Cadena'].astype(str).copy()\n",
    "    data['EAN'] = data['EAN'].astype(str).copy()    \n",
    "    for col in ['Unidades', 'Costos B2B']:\n",
    "        data[col] = data[col].map(clean_numbers).copy()\n",
    "    data['ID_SaSt'] = data['EAN'].astype(str) + data['Cód. Cadena'].astype(str) + data['Cadena'] + data['Local']  \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_stores(url, header):\n",
    "    resp_stores = requests.get(url, headers=header)\n",
    "    if resp_stores.status_code != 200:\n",
    "        print(\"Oh, oh, problems body\")\n",
    "    else:\n",
    "        df = pd.read_excel(resp_stores.json()['url'], sep='\\t')\n",
    "        ind_min = df[df.iloc[:,7].notnull()].index.min()\n",
    "        cols = df.iloc[9,:].tolist()\n",
    "        data = df.loc[ind_min + 2:].copy()\n",
    "        data.reset_index(drop=True, inplace=True)\n",
    "        data.rename(dict(zip(df.columns.tolist(), cols)), inplace=True, axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_stock(dates, chain, url, header, body):\n",
    "    df_stock = pd.DataFrame()\n",
    "    hierarchy_stock['Cadena'] = chain\n",
    "    for date in dates:\n",
    "        body[\"dates\"] = [date.strftime('%Y-%m-%d')]\n",
    "        resp_stock = requests.post(url, data=json.dumps(body), headers=header)\n",
    "        if resp_stock.status_code != 200:\n",
    "            print(\"Oh, oh, adventurous, problems in \" + date.strftime('%d/%m/%Y') + ' :S')\n",
    "            pass\n",
    "        else:\n",
    "            resp_page = urlopen(resp_stock.json()['download_url'])\n",
    "            zip_file = ZipFile(BytesIO(resp_page.read()))\n",
    "            df = pd.read_csv(zip_file.open(zip_file.namelist()[0]), encoding='latin-1', sep=';')\n",
    "            df_stock = pd.concat([df_stock, df], axis=0)\n",
    "    df_stock.reset_index(drop=True, inplace=True)\n",
    "    return df_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_stock(dates, chains):\n",
    "    df = pd.DataFrame()\n",
    "    for date in dates:\n",
    "        df = pd.concat([df, download_stock(dates=[date], chain=[], url=url_stock, header=headers_stock, body=body_stock)], axis=0)\n",
    "        for chain in chains:\n",
    "            chain_stock = pd.DataFrame()\n",
    "            days = 0\n",
    "            if chain not in df['Cadena'].unique():                \n",
    "                while chain_stock.shape[0] == 0:\n",
    "                    days += 1            \n",
    "                    chain_stock = download_stock(dates=[date - timedelta(days=days)], chain=[chain], url=url_stock, header=headers_stock, body=body_stock)\n",
    "                    sleep(17)\n",
    "                    if days > 7:\n",
    "                        break\n",
    "            try:\n",
    "                df = pd.concat([df, chain_stock[chain_stock['Cadena'] == chain]], axis=0)\n",
    "            except:\n",
    "                pass\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stock(data):\n",
    "    data_clean = data[['Fechas', 'EAN', 'Cadena', 'Sub Cadena', 'Local', 'Stock Locales en Unidades', 'Stock CD en Unidades', 'Stock en Tránsito en Unidades', 'Stock Total en Unidades']].copy()\n",
    "    for col in ['Stock Locales en Unidades', 'Stock CD en Unidades', 'Stock en Tránsito en Unidades', 'Stock Total en Unidades']:\n",
    "        data_clean[col] = data_clean[col].map(clean_numbers)\n",
    "    data_clean['ID_SaSt'] = data['EAN'].astype(str) + data['Cód. Cadena'].astype(str) + data['Cadena'] + data['Local']\n",
    "    data_clean['ID_StSt'] = data['Cadena'] + data['Sub Cadena'] + data['Local']\n",
    "    return data_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill = lambda col1, col2: col1 if pd.isnull(col2) else (col2 if pd.isnull(col1) else col1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relate_dates(df1, df2):\n",
    "    d = {}\n",
    "    for date1 in df1:\n",
    "        for date2 in df2:\n",
    "            d11 = clean_date(date1.split(' ')[2])\n",
    "            d12 = clean_date(date1.split(' ')[-1])\n",
    "            d2 = clean_date(date2)\n",
    "            if d11 <= d2 <= d12:\n",
    "                d[d2.strftime('%d-%m-%Y')] = d12.strftime('%d-%m-%Y')\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_data(sales, stock, stores, df_ppst):\n",
    "        join = pd.merge(sales, stock, on='ID_SaSt', how='outer')\n",
    "        join['Cadena'] = join['Cadena_y'].combine(join['Cadena_x'], fill)\n",
    "        join['Sub Cadena'] = join['Sub Cadena_y'].combine(join['Sub Cadena_x'], fill)\n",
    "        join['Local'] = join['Local_y'].combine(join['Local_x'], fill)\n",
    "        join['EAN'] = join['EAN_y'].combine(join['EAN_x'], fill)\n",
    "        join['Fecha'] = join['Fecha_y'].combine(join['Fecha_x'], fill)\n",
    "        join.drop(['Cadena_x', 'Cadena_y', 'Sub Cadena_x', 'Sub Cadena_y', 'Local_x', 'Local_y', 'EAN_x', 'EAN_y', 'Fecha_x', 'Fecha_y', 'ID_SaSt', 'ID_StSt'], axis=1, inplace=True)\n",
    "        join.fillna(0, inplace=True)\n",
    "        join2 = pd.merge(join, stores, on='Local', how='left')\n",
    "        join2.rename({'EAN':'ProPstCodBarras'}, axis=1, inplace=True)\n",
    "        join2 = join2[join2['ProPstCodBarras'] != 'No Definido'].copy()\n",
    "        join2['ProPstCodBarras'] = join2['ProPstCodBarras'].astype('int64').astype(str)\n",
    "        join3 = pd.merge(join2, df_ppst, on='ProPstCodBarras', how='left')\n",
    "        return join3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def status(df1, df2, df3):\n",
    "    cols = ['Unidades', 'Costos B2B', 'Stock Locales en Unidades',\n",
    "           'Stock CD en Unidades', 'Stock en Tránsito en Unidades',\n",
    "           'Stock Total en Unidades']\n",
    "\n",
    "    for col in cols:\n",
    "        try:\n",
    "            sum_equals = (df1[col].sum() == df2[col].sum())\n",
    "            if sum_equals == False:\n",
    "                diff = (df1[col].sum() - df2[col].sum())\n",
    "        except:\n",
    "            sum_equals = df1[col].sum() == df3[col].sum()\n",
    "            if sum_equals == False:\n",
    "                diff = (df1[col].sum() - df3[col].sum())\n",
    "        if sum_equals == False:\n",
    "            print(sum_equals, \" - \", col, '  -  Difference:', diff)\n",
    "        else:\n",
    "            print(sum_equals, \" - \", col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí es donde hace casi toda la magia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%notify -m \"¡Descarga de ECUADOR lista!\"\n",
    "%%time\n",
    "# Semana ISV = Semana Genomma - 1\n",
    "final = pd.DataFrame()\n",
    "df_sales = {}\n",
    "data_sales = {}\n",
    "df_stock = {}\n",
    "data_stock = {}\n",
    "#df_stores = pd.read_excel('../../1Data/2Catalogue/SucID_41_43.xlsx')\n",
    "df_stores = download_stores(url_stores, headers_stores)\n",
    "stores = df_stores[['Local', 'Suc. ID']].copy()\n",
    "weeks = [datetime.today().isocalendar()[1] - i for i in range(3, 1, -1)]\n",
    "for week in weeks:\n",
    "    ## Download the sales data\n",
    "    df_sales[str(week)] = download_sales(week, url=sales['url_sales'], body=body_sales, header=sales['headers_sales'])\n",
    "    ## Clean it\n",
    "    data_sales[str(week)] = clean_sales(df_sales[str(week)])\n",
    "    ## Download the stock data\n",
    "    df_stock[str(week)] = iterate_stock([clean_date(df_sales[str(week)]['Semanas'].unique()[0][-10:])], df_sales[str(week)]['Cadena'].unique().tolist())       \n",
    "    ## Clean it\n",
    "    data_stock[str(week)] = clean_stock(df_stock[str(week)])\n",
    "    ## Verify the stock data\n",
    "    print(\"Total de stock a la semana \" + str(week + 1) + \":\", \"\\n\")\n",
    "    print(pd.pivot_table(data_stock[str(week)], index=['Cadena'], columns=['Fechas'], values=['Stock Locales en Unidades'], aggfunc='sum'))\n",
    "    ## Assign a date to sales data and stock data\n",
    "    dict_dates = relate_dates(data_sales[str(week)]['Semanas'].unique(), data_stock[str(week)]['Fechas'].unique())\n",
    "    ## Format the date to sales data\n",
    "    sellout = data_sales[str(week)][['Semanas', 'Cadena', 'Sub Cadena', 'Local','EAN','Unidades', 'Costos B2B', 'ID_SaSt']].copy()\n",
    "    sellout['Fecha'] = sellout['Semanas'].apply(lambda x: x[-10:]).copy()\n",
    "    sellout.drop(['Semanas'], axis=1, inplace=True)\n",
    "    ## Format the date to stock data\n",
    "    stock = data_stock[str(week)].copy()\n",
    "    stock['Fecha'] = data_stock[str(week)]['Fechas'].map(dict_dates)\n",
    "    stock.drop(['Fechas'], axis=1, inplace=True)\n",
    "    ## Merge sales, stock and stores data\n",
    "    all_data = join_data(sellout, stock, stores, df_ppst)\n",
    "    ## We verify some fields\n",
    "    print('\\n', 'Missings por columna:\\n', all_data.isnull().sum())\n",
    "    print('\\n', 'Códigos de Barra sin ProPstID  ', all_data[all_data['ProPstID'].isnull()]['ProPstCodBarras'].unique(), '\\n')\n",
    "    status(all_data, data_stock[str(week)], data_sales[str(week)])\n",
    "    ## We concant into a single variable\n",
    "    final = pd.concat([final, all_data], axis=0)\n",
    "    print('\\n\\n')\n",
    "    print('-----------------------------------------------------------------------')\n",
    "    print('\\n\\n')\n",
    "final.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usualmente cuando las sucursales (_Suc. ID_) no están en ISV, vienen como _\"No Definidas\"_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26913, 13)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0 Farmamia - Local genérico'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final['Local'][final['Suc. ID'].astype(str).str.contains('No')].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.loc[final['Suc. ID'].astype(str).str.contains('No'), 'Suc. ID'] = '146777'\n",
    "final.loc[final['Suc. ID'] == '0', 'Suc. ID'] = '146100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 34094 \n",
      " max: 146777\n"
     ]
    }
   ],
   "source": [
    "print('min:', final['Suc. ID'].astype('int64').min(), '\\n','max:', final['Suc. ID'].astype('int64').max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['42', '43'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sales.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unidades', 'Costos B2B', 'Stock Locales en Unidades',\n",
       "       'Stock CD en Unidades', 'Stock en Tránsito en Unidades',\n",
       "       'Stock Total en Unidades', 'Cadena', 'Sub Cadena', 'Local',\n",
       "       'ProPstCodBarras', 'Fecha', 'Suc. ID', 'ProPstID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['25-10-2020', '01-11-2020'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final['Fecha'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['42', '43'])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stock.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = {'Unidades':'SoutCantDesp',\n",
    "             'Stock Locales en Unidades':'SoutCantExist',\n",
    "             'Stock CD en Unidades':'SoutCantCedis',\n",
    "             'Stock en Tránsito en Unidades':'SoutCantTrans',\n",
    "             'Stock Total en Unidades':'SoutCantInv',\n",
    "             'Costos B2B':'SoutMontoDesp',\n",
    "             'Stock Locales en Precio Lista':'SoutMontoExist',\n",
    "             'Stock CD en Precio Lista':'SoutMontoCedis',\n",
    "             'Stock Total en Precio Lista':'SoutMontoInv',             \n",
    "             'EAN_x':'ProPstCodBarras',\n",
    "             'Suc. ID':'SucID',\n",
    "             'Pro. Pst. ID':'ProPstID'}\n",
    "\n",
    "final.rename(new_names, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['TmpFecha'] = final['Fecha'].map(clean_date).astype(str)\n",
    "\n",
    "final = pd.merge(final, df_tmpid, on='TmpFecha', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['SoutCantStaple'] = 0\n",
    "final['SoutMontoTrans'] = 0\n",
    "final['SoutMontoStaple'] = 0\n",
    "final['SoutMontoExist'] = 0\n",
    "final['SoutMontoCedis'] = 0\n",
    "final['SoutMontoTrans'] = 0\n",
    "final['SoutMontoStaple'] = 0\n",
    "final['SoutMontoInv'] = 0\n",
    "final['SoutMontoCteDesp'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = pd.pivot_table(final, index=['ProPstID', 'SucID', 'TmpID'], values=['SoutCantDesp', 'SoutCantExist', 'SoutCantCedis', 'SoutCantTrans', 'SoutCantStaple', 'SoutCantInv', 'SoutMontoDesp', 'SoutMontoExist', 'SoutMontoCedis', 'SoutMontoTrans', 'SoutMontoStaple', 'SoutMontoInv', 'SoutMontoCteDesp'], aggfunc='sum').reset_index().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26913, 22)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26788, 16)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veificamos que no haya _Pro. Pst. ID_ en 0 (que sigificaría un error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26788, 16)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProPstID              int64\n",
       "SucID                object\n",
       "TmpID                 int64\n",
       "SoutCantCedis       float64\n",
       "SoutCantDesp        float64\n",
       "SoutCantExist       float64\n",
       "SoutCantInv         float64\n",
       "SoutCantStaple        int64\n",
       "SoutCantTrans       float64\n",
       "SoutMontoCedis        int64\n",
       "SoutMontoCteDesp      int64\n",
       "SoutMontoDesp       float64\n",
       "SoutMontoExist        int64\n",
       "SoutMontoInv          int64\n",
       "SoutMontoStaple       int64\n",
       "SoutMontoTrans        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 633 \n",
      " max: 8479\n"
     ]
    }
   ],
   "source": [
    "print('min:',data_final['ProPstID'].min(), '\\n','max:', data_final['ProPstID'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 34094 \n",
      " max: 146777\n"
     ]
    }
   ],
   "source": [
    "print('min:',data_final['SucID'].astype('int64').min(), '\\n','max:', data_final['SucID'].astype('int64').max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProPstID            0\n",
       "SucID               0\n",
       "TmpID               0\n",
       "SoutCantCedis       0\n",
       "SoutCantDesp        0\n",
       "SoutCantExist       0\n",
       "SoutCantInv         0\n",
       "SoutCantStaple      0\n",
       "SoutCantTrans       0\n",
       "SoutMontoCedis      0\n",
       "SoutMontoCteDesp    0\n",
       "SoutMontoDesp       0\n",
       "SoutMontoExist      0\n",
       "SoutMontoInv        0\n",
       "SoutMontoStaple     0\n",
       "SoutMontoTrans      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last validations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No debe existir duplicados en estas 4 columnas, sino sugeriría que no corrímos bien el *pivot_table*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final[['ProPstID', 'SucID', 'TmpID']].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo verifico una vez más XD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20201025, 20201101], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final['TmpID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = {'Unidades':'SoutCantDesp',\n",
    "            'Stock Locales en Unidades':'SoutCantExist',\n",
    "            'Stock CD en Unidades':'SoutCantCedis',\n",
    "            'Stock en Tránsito en Unidades':'SoutCantTrans',\n",
    "            'Stock Total en Unidades':'SoutCantInv',\n",
    "            'Costos B2B':'SoutMontoDesp'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sales_tot = pd.concat([data_sales['43'], data_sales['42']], axis=0)\n",
    "data_stock_tot = pd.concat([data_stock['43'], data_stock['42']], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True  -  Unidades\n",
      "False  -  Stock Locales en Unidades   ||  Difference: 5.820766091346741e-11\n",
      "True  -  Stock CD en Unidades\n",
      "True  -  Stock en Tránsito en Unidades\n",
      "False  -  Stock Total en Unidades   ||  Difference: 5.820766091346741e-11\n",
      "True  -  Costos B2B\n"
     ]
    }
   ],
   "source": [
    "for k, v in new_cols.items():\n",
    "    try:\n",
    "        status = (data_final[v].sum() == data_stock_tot[k].sum())\n",
    "        if status == False:\n",
    "            diff = (data_final[v].sum() - data_stock_tot[k].sum())\n",
    "    except:\n",
    "        status = data_final[v].sum() == data_sales_tot[k].sum()\n",
    "        if status == False:\n",
    "            diff = (data_final[v].sum() - data_sales_tot[k].sum())\n",
    "    if status == False:\n",
    "        print(status, \" - \", k, '  ||  Difference:', diff)\n",
    "    else:\n",
    "        print(status, \" - \", k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si hay *SucID* en 0, también sugiere un error:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vuelvo a verificar, jajaja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProPstID</th>\n",
       "      <th>SucID</th>\n",
       "      <th>TmpID</th>\n",
       "      <th>SoutCantCedis</th>\n",
       "      <th>SoutCantDesp</th>\n",
       "      <th>SoutCantExist</th>\n",
       "      <th>SoutCantInv</th>\n",
       "      <th>SoutCantStaple</th>\n",
       "      <th>SoutCantTrans</th>\n",
       "      <th>SoutMontoCedis</th>\n",
       "      <th>SoutMontoCteDesp</th>\n",
       "      <th>SoutMontoDesp</th>\n",
       "      <th>SoutMontoExist</th>\n",
       "      <th>SoutMontoInv</th>\n",
       "      <th>SoutMontoStaple</th>\n",
       "      <th>SoutMontoTrans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ProPstID, SucID, TmpID, SoutCantCedis, SoutCantDesp, SoutCantExist, SoutCantInv, SoutCantStaple, SoutCantTrans, SoutMontoCedis, SoutMontoCteDesp, SoutMontoDesp, SoutMontoExist, SoutMontoInv, SoutMontoStaple, SoutMontoTrans]\n",
       "Index: []"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final[data_final['SucID'].str.contains('No')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_upgrade = list(zip(*map(data_final.get, data_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ProPstID', 'SucID', 'TmpID', 'SoutCantCedis', 'SoutCantDesp',\n",
       "       'SoutCantExist', 'SoutCantInv', 'SoutCantStaple', 'SoutCantTrans',\n",
       "       'SoutMontoCedis', 'SoutMontoCteDesp', 'SoutMontoDesp', 'SoutMontoExist',\n",
       "       'SoutMontoInv', 'SoutMontoStaple', 'SoutMontoTrans'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20201025, 20201101], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final['TmpID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33477.1292"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final[data_final['TmpID'] == 20201025]['SoutCantDesp'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88450 Record inserted successfully into Laptop table\n",
      "MySQL connection is closed\n",
      "Wall time: 18.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "try:\n",
    "    connection = mysql.connector.connect(user='admin', \n",
    "                                         password='g3N0mmaLABi$ntelligence',\n",
    "                                         host='genommalab-businessintelligence.cgkb305m9bb6.us-east-1.rds.amazonaws.com',\n",
    "                                         database='businessintelligence')\n",
    "    mySql_insert_query = \"\"\"INSERT INTO Fact_Desplazamiento_SemanalEcu (ProPstID, SucID, TmpID, SoutCantCedis, SoutCantDesp, SoutCantExist, SoutCantInv,  SoutCantStaple, SoutCantTrans, SoutMontoCedis, SoutMontoCteDesp, SoutMontoDesp, SoutMontoExist, SoutMontoInv, SoutMontoStaple, SoutMontoTrans) \n",
    "                           VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s) \"\"\"\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "    cursor.executemany(mySql_insert_query, data_upgrade)\n",
    "    connection.commit()\n",
    "    print(cursor.rowcount, \"Record inserted successfully into Laptop table\")\n",
    "    cursor.close()\n",
    "\n",
    "except mysql.connector.Error as error:\n",
    "    print(\"Failed to insert record into Laptop table {}\".format(error))\n",
    "\n",
    "finally:\n",
    "    if (connection.is_connected()):\n",
    "        connection.close()\n",
    "        print(\"MySQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda8f2870ef7b8b4a659a1cfb9279b52c39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
